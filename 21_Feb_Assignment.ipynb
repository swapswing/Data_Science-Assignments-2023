{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "95eb523a-379b-43f4-9d9d-eefb6c3b9a2e",
   "metadata": {},
   "source": [
    " # Q1. What is Web Scraping? Why is it Used? Give three areas where Web Scraping is used to get data.\n",
    "\n",
    " Ans.Web Scraping refers to the automated process of extracting data from websites. It involves parsing the HTML of a web page and extracting the relevant information for various purposes. Web scraping is used for:\n",
    "\n",
    "Business Intelligence: Gathering data from competitor websites for market analysis, pricing strategies, etc.\n",
    "Research: Collecting data from academic sources, news websites, or social media platforms for research purposes.\n",
    "Aggregation: Compiling data from multiple sources into a single database or application, such as job listings or real estate listings."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8807e94-a9e3-4730-a30f-a4443926d626",
   "metadata": {},
   "source": [
    "# Q2. What are the different methods used for Web Scraping?\n",
    "Ans.\n",
    "Different methods for web scraping include:\n",
    "\n",
    "Using Libraries/Frameworks: Such as BeautifulSoup, Scrapy, or Puppeteer.\n",
    "HTTP Request Libraries: Like Requests in Python or Axios in JavaScript.\n",
    "APIs: Some websites provide APIs (Application Programming Interfaces) for accessing their data directly.\n",
    "Headless Browsers: Tools like Selenium can automate browsers to interact with web pages and extract data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bb4a411-114a-4cf8-bf34-b9ae321fb688",
   "metadata": {},
   "source": [
    "# Q3. What is Beautiful Soup? Why is it used?\n",
    "Ans. Beautiful Soup is a Python library used for parsing HTML and XML documents, extracting data, and navigating the parsed tree. It provides a simple way to handle HTML and is useful for web scraping because it allows easy extraction of data from HTML pages, handling of tag structures, and navigating through the document."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2e6c6a8-82f6-4146-a691-71b7a2c0bfce",
   "metadata": {},
   "source": [
    "# Q4. Why is Flask used in this Web Scraping project?\n",
    "\n",
    "Flask is a lightweight Python web framework that is commonly used for building web applications, including those involving web scraping. In a web scraping project, Flask can be used for several purposes:\n",
    "\n",
    "Web Interface: Providing a user interface to input URLs or parameters for scraping.\n",
    "Data Presentation: Displaying scraped data in a structured format on a web page.\n",
    "API Development: Creating APIs to serve scraped data to other applications.\n",
    "Integration: Connecting the scraping script with a web application for automation or scheduling tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34e494f2-3240-493f-ab7e-ba0db020f016",
   "metadata": {},
   "source": [
    "# Q5. Write the names of AWS services used in this project. Also, explain the use of each service.\n",
    "\n",
    "In a web scraping project hosted on AWS (Amazon Web Services), common services that might be used include:\n",
    "\n",
    "EC2 (Elastic Compute Cloud): Provides resizable compute capacity in the cloud. It can be used to host the web scraping script, run it periodically, or handle concurrent scraping tasks.\n",
    "\n",
    "S3 (Simple Storage Service): Provides object storage with high durability and scalability. It can be used to store scraped data files, logs, or other artifacts generated during scraping.\n",
    "\n",
    "Lambda: AWS Lambda lets you run code without provisioning or managing servers. It can be used to run lightweight scraping tasks or to trigger scraping based on events (e.g., new data availability).\n",
    "\n",
    "CloudWatch: Monitors AWS resources and applications in real-time. It can be used to monitor the health and performance of scraping tasks, trigger alerts, and manage logs.\n",
    "\n",
    "RDS (Relational Database Service): Offers managed database services for several database engines. It can be used to store structured data obtained from web scraping, providing scalability, reliability, and easy management.\n",
    "\n",
    "Each of these services plays a crucial role in supporting different aspects of a web scraping project hosted on AWS, from storing and processing data to managing infrastructure and monitoring performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05a6b65d-25c2-4d07-a87e-f3e8b5e42601",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
